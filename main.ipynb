{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chris2tg/PS/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0zuYQzwiO8Z",
        "colab_type": "text"
      },
      "source": [
        "# M2608.001300 Machine Learning<br> Assignment #5 Final Projects (Pytorch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri0oOICuC64e",
        "colab_type": "text"
      },
      "source": [
        "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJfG1l3RC_c3",
        "colab_type": "text"
      },
      "source": [
        "**For understanding of this work, please carefully look at given PPT file.**\n",
        "\n",
        "Note: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9yv4oGGDbmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "341bf2a1-3c73-4da0-ac38-04427d49afa6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "!pip3 install resnet\n",
        "import resnet\n",
        "import torchvision.models as models\n",
        "#!ls '/content/drive/My Drive/Data'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: resnet in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: keras>=2.0 in /usr/local/lib/python3.6/dist-packages (from resnet) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->resnet) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acvGcUAaEkxe",
        "colab_type": "text"
      },
      "source": [
        "Load datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcPk4u8qGZHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89521f10-24cc-46e9-b78f-dfc1a3f97bd4"
      },
      "source": [
        "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "NONE = ['NONE'] # label for empty space\n",
        "ALL_CHAR_SET = NUMBER + ALPHABET + NONE\n",
        "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
        "MAX_CAPTCHA = 7\n",
        "\n",
        "print(ALL_CHAR_SET.index('NONE'))\n",
        "\n",
        "def encode(a):\n",
        "    onehot = [0]*ALL_CHAR_SET_LEN\n",
        "    idx = ALL_CHAR_SET.index(a)\n",
        "    onehot[idx] += 1\n",
        "    return onehot\n",
        "\n",
        "# modified dataset class\n",
        "class Mydataset(Dataset):\n",
        "    def __init__(self, img_path, label_path, is_train=True, transform=None):\n",
        "        self.path = img_path\n",
        "        self.label_path = label_path\n",
        "        if is_train: \n",
        "            self.img = os.listdir(self.path)[:1000]\n",
        "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
        "        else: \n",
        "            self.img = os.listdir(self.path)[:1000]\n",
        "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
        "        \n",
        "        self.transform = transform\n",
        "        self.max_length = MAX_CAPTCHA\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img[idx]\n",
        "        img = Image.open(f'{self.path}/{self.img[idx]}')\n",
        "        img = img.convert('L')\n",
        "        label = self.labels[idx]\n",
        "        label_oh = []\n",
        "        # one-hot for each character\n",
        "        for i in range(self.max_length):\n",
        "            if i < len(label):\n",
        "                label_oh += encode(label[i])\n",
        "            else:\n",
        "                #label_oh += [0]*ALL_CHAR_SET_LEN\n",
        "                label_oh += encode('NONE')\n",
        "            \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, np.array(label_oh), label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([160, 60]),\n",
        "    transforms.ToTensor(),\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "])\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EFtlQyubGJZb",
        "colab": {}
      },
      "source": [
        "\"\"\"Loading DATA\"\"\"\n",
        "# Change to your own data folder path!\n",
        "gPath = '/content/drive/My Drive/'\n",
        "\n",
        "train_ds = Mydataset(gPath+'Data/train/', gPath+'Data/train.txt',transform=transform)\n",
        "test_ds = Mydataset(gPath+'Data/test/', gPath+'Data/test.txt',False, transform)\n",
        "#print(train_ds.__len__())\n",
        "train_dl = DataLoader(train_ds, batch_size=32, num_workers=4) #128 no.\n",
        "test_dl = DataLoader(test_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "#for i,j in enumerate(train_dl):\n",
        "#  print(j[1][0])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka5SgX6VIWcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"To CUDA for local run\"\"\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#GPUID = '4' # define GPUID\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJaHW3wSENjY",
        "colab_type": "text"
      },
      "source": [
        "Problem 1: Design LSTM model for catcha image recognition. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rHEe3XmBFQHq",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, cnn_dim, hidden_size, vocab_size, num_layers=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        # define the properties\n",
        "        self.cnn_dim = cnn_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # lstm cell\n",
        "        self.lstm_cell = nn.LSTMCell(input_size=self.vocab_size, hidden_size=hidden_size)\n",
        "    \n",
        "        # output fully connected layer\n",
        "        self.fc_in = nn.Linear(in_features=self.cnn_dim, out_features=self.vocab_size)\n",
        "        self.fc_out = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
        "    \n",
        "        # embedding layer\n",
        "        self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.vocab_size)\n",
        "    \n",
        "        # activations\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    def forward(self, features, captions):\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        cnn_dim = features.size(1)\n",
        "\n",
        "        hidden_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
        "        cell_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
        "    \n",
        "        # define the output tensor placeholder\n",
        "        outputs = torch.empty((batch_size, captions.size(1), self.vocab_size)).cuda()\n",
        "\n",
        "        # embed the captions\n",
        "        captions_embed = self.embed(captions)\n",
        "\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "        return outputs \n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM2vL2PTFeEt",
        "colab_type": "text"
      },
      "source": [
        "Problem 2: \n",
        "\n",
        "*   1.Connect CNN model to the designed LSTM model.\n",
        "*   2.Replace ResNet to your own CNN model from Assignment3.\n",
        "\n",
        "\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwgpQ1aiFq2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\"\"\"ResNet\"\"\"\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
        "            nn.BatchNorm2d(n1x1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.b2 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n3x3red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n3x3),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.b3 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n5x5red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 3x3 pool -> 1x1 conv branch\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_planes),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1,y2,y3,y4], 1)\n",
        "class BetterNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BetterNet, self).__init__()\n",
        "        self.preprocess = nn.Sequential(\n",
        "           nn.Conv2d(1, 192, kernel_size=3, padding=1),\n",
        "           nn.BatchNorm2d(192),\n",
        "           nn.ReLU(True),\n",
        "            #nn.Conv2d(3, 64, kernel_size=7, padding=3),\n",
        "            #nn.BatchNorm2d(64),\n",
        "            #nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            #nn.BatchNorm2d(192),\n",
        "            #nn.ReLU(True),\n",
        "        )\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.a_1 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
        "        self.b_1 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.a_2 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
        "        self.b_2 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
        "        self.c_2 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
        "        self.d_2 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
        "        self.e_2 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.a_3 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.b_3 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "        self.linear = nn.Linear(270336, 259) #1024,10 no ALL_CHAR_SET_LEN\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.preprocess(x)\n",
        "        out = self.a_1(out)\n",
        "        out = self.b_1(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a_2(out)\n",
        "        out = self.b_2(out)\n",
        "        out = self.c_2(out)\n",
        "        out = self.d_2(out)\n",
        "        out = self.e_2(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a_3(out)\n",
        "        out = self.b_3(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "#CNN\n",
        "betternet = models.resnet18(pretrained=False)\n",
        "#betternet=BetterNet()\n",
        "betternet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "betternet.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)\n",
        "betternet = betternet.to(device)\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "\n",
        "       \n",
        "# LSTM\n",
        "cnn_dim=512 #resnet18-512\n",
        "hidden_size=8\n",
        "vocab_size=37 #ALL_CHAR_SET_LEN\n",
        "lstm = LSTM(cnn_dim=cnn_dim, hidden_size=hidden_size, vocab_size=vocab_size)\n",
        "lstm = lstm.to(device)\n",
        "# loss, optimizer\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "loss_func = nn.MultiLabelSoftMarginLoss()\n",
        "cnn_optim = torch.optim.Adam(betternet.parameters(), lr=0.001)\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoeTIkXjHJIE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSvn2ZXZa6kI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "997702bf-9fc4-4700-db1f-d21bbc62af21"
      },
      "source": [
        "PATH = './better_net.pth'\n",
        "optimizer = optim.SGD(betternet.parameters(), lr=0.001, momentum=0.9)\n",
        "def train(net, trainloader, max_epoch, crit, opt, model_path='./cifar_net.pth'):\n",
        "\n",
        "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs  =  data[0]\n",
        "            labels = data[1]\n",
        "        \n",
        "            # Training on GPU\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = crit(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "    torch.save(net.state_dict(), model_path)\n",
        "    print('Saved Trained Model')\n",
        "train(betternet, train_dl, 2, loss_func, cnn_optim, PATH)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "Saved Trained Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0uCexwRHsNz",
        "colab_type": "text"
      },
      "source": [
        "Problem3: Find hyper-parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibfVzKZeH1yC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8dae0404-245f-4da4-ab3d-041aac3e14ca"
      },
      "source": [
        "\"\"\"TRAINING\"\"\"\n",
        "\n",
        "\n",
        "print_interval = 32\n",
        "max_epoch = 40 #40,1000\n",
        "#print(train_dl.__len__())\n",
        "for epoch in range(max_epoch):\n",
        "    for step, i in enumerate(train_dl):\n",
        "        img, label_oh, label = i\n",
        "        img = Variable(img).cuda()\n",
        "        label_oh = Variable(label_oh.float()).cuda()\n",
        "        batch_size, _ = label_oh.shape #4*259\n",
        "        #pred, feature = betternet(img)\n",
        "        pred = betternet(img)\n",
        "        loss = loss_func(pred, label_oh)\n",
        "        cnn_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        cnn_optim.step()###should be changed\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "        if (step+1)%print_interval == 0:\n",
        "            print('epoch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 step: 4 loss: 0.06781540811061859\n",
            "epoch: 1 step: 8 loss: 0.06915921717882156\n",
            "epoch: 1 step: 12 loss: 0.07085311412811279\n",
            "epoch: 1 step: 16 loss: 0.07408474385738373\n",
            "epoch: 1 step: 20 loss: 0.06863550841808319\n",
            "epoch: 1 step: 24 loss: 0.07256986200809479\n",
            "epoch: 1 step: 28 loss: 0.07025358080863953\n",
            "epoch: 1 step: 32 loss: 0.05768401548266411\n",
            "epoch: 2 step: 4 loss: 0.06810705363750458\n",
            "epoch: 2 step: 8 loss: 0.06930367648601532\n",
            "epoch: 2 step: 12 loss: 0.07068891078233719\n",
            "epoch: 2 step: 16 loss: 0.0740017220377922\n",
            "epoch: 2 step: 20 loss: 0.06857163459062576\n",
            "epoch: 2 step: 24 loss: 0.07256253808736801\n",
            "epoch: 2 step: 28 loss: 0.07009196281433105\n",
            "epoch: 2 step: 32 loss: 0.05672560632228851\n",
            "epoch: 3 step: 4 loss: 0.06810156255960464\n",
            "epoch: 3 step: 8 loss: 0.06945932656526566\n",
            "epoch: 3 step: 12 loss: 0.07072735577821732\n",
            "epoch: 3 step: 16 loss: 0.07395747303962708\n",
            "epoch: 3 step: 20 loss: 0.06858538091182709\n",
            "epoch: 3 step: 24 loss: 0.07258615642786026\n",
            "epoch: 3 step: 28 loss: 0.0700136199593544\n",
            "epoch: 3 step: 32 loss: 0.05650411546230316\n",
            "epoch: 4 step: 4 loss: 0.06813385337591171\n",
            "epoch: 4 step: 8 loss: 0.0694546326994896\n",
            "epoch: 4 step: 12 loss: 0.0707266554236412\n",
            "epoch: 4 step: 16 loss: 0.07397512346506119\n",
            "epoch: 4 step: 20 loss: 0.06855814158916473\n",
            "epoch: 4 step: 24 loss: 0.07258285582065582\n",
            "epoch: 4 step: 28 loss: 0.06999509036540985\n",
            "epoch: 4 step: 32 loss: 0.05643817409873009\n",
            "epoch: 5 step: 4 loss: 0.06813278794288635\n",
            "epoch: 5 step: 8 loss: 0.06945986300706863\n",
            "epoch: 5 step: 12 loss: 0.0707148015499115\n",
            "epoch: 5 step: 16 loss: 0.07397590577602386\n",
            "epoch: 5 step: 20 loss: 0.0685538798570633\n",
            "epoch: 5 step: 24 loss: 0.0725909173488617\n",
            "epoch: 5 step: 28 loss: 0.06997619569301605\n",
            "epoch: 5 step: 32 loss: 0.05642615631222725\n",
            "epoch: 6 step: 4 loss: 0.06813617050647736\n",
            "epoch: 6 step: 8 loss: 0.06944863498210907\n",
            "epoch: 6 step: 12 loss: 0.07071293890476227\n",
            "epoch: 6 step: 16 loss: 0.07398614287376404\n",
            "epoch: 6 step: 20 loss: 0.06854403018951416\n",
            "epoch: 6 step: 24 loss: 0.07259097695350647\n",
            "epoch: 6 step: 28 loss: 0.06997189670801163\n",
            "epoch: 6 step: 32 loss: 0.05642234534025192\n",
            "epoch: 7 step: 4 loss: 0.0681333988904953\n",
            "epoch: 7 step: 8 loss: 0.0694483295083046\n",
            "epoch: 7 step: 12 loss: 0.07071328163146973\n",
            "epoch: 7 step: 16 loss: 0.07397770881652832\n",
            "epoch: 7 step: 20 loss: 0.06854748725891113\n",
            "epoch: 7 step: 24 loss: 0.07259100675582886\n",
            "epoch: 7 step: 28 loss: 0.06996700912714005\n",
            "epoch: 7 step: 32 loss: 0.056418873369693756\n",
            "epoch: 8 step: 4 loss: 0.06813537329435349\n",
            "epoch: 8 step: 8 loss: 0.06944748759269714\n",
            "epoch: 8 step: 12 loss: 0.07070931792259216\n",
            "epoch: 8 step: 16 loss: 0.07398533821105957\n",
            "epoch: 8 step: 20 loss: 0.06854350119829178\n",
            "epoch: 8 step: 24 loss: 0.07259516417980194\n",
            "epoch: 8 step: 28 loss: 0.06995877623558044\n",
            "epoch: 8 step: 32 loss: 0.05642126500606537\n",
            "epoch: 9 step: 4 loss: 0.06813337653875351\n",
            "epoch: 9 step: 8 loss: 0.06944271922111511\n",
            "epoch: 9 step: 12 loss: 0.07070835679769516\n",
            "epoch: 9 step: 16 loss: 0.07398617267608643\n",
            "epoch: 9 step: 20 loss: 0.06854198127985\n",
            "epoch: 9 step: 24 loss: 0.07259189337491989\n",
            "epoch: 9 step: 28 loss: 0.06996147334575653\n",
            "epoch: 9 step: 32 loss: 0.05642037093639374\n",
            "epoch: 10 step: 4 loss: 0.06813320517539978\n",
            "epoch: 10 step: 8 loss: 0.06944151222705841\n",
            "epoch: 10 step: 12 loss: 0.07070928812026978\n",
            "epoch: 10 step: 16 loss: 0.07398328185081482\n",
            "epoch: 10 step: 20 loss: 0.06854382157325745\n",
            "epoch: 10 step: 24 loss: 0.07259362936019897\n",
            "epoch: 10 step: 28 loss: 0.06995655596256256\n",
            "epoch: 10 step: 32 loss: 0.05642298609018326\n",
            "epoch: 11 step: 4 loss: 0.06813431531190872\n",
            "epoch: 11 step: 8 loss: 0.06944287568330765\n",
            "epoch: 11 step: 12 loss: 0.07070782780647278\n",
            "epoch: 11 step: 16 loss: 0.07398436963558197\n",
            "epoch: 11 step: 20 loss: 0.06854400783777237\n",
            "epoch: 11 step: 24 loss: 0.07259620726108551\n",
            "epoch: 11 step: 28 loss: 0.06995411217212677\n",
            "epoch: 11 step: 32 loss: 0.05642145127058029\n",
            "epoch: 12 step: 4 loss: 0.06813374161720276\n",
            "epoch: 12 step: 8 loss: 0.06944280862808228\n",
            "epoch: 12 step: 12 loss: 0.07070444524288177\n",
            "epoch: 12 step: 16 loss: 0.07399191707372665\n",
            "epoch: 12 step: 20 loss: 0.06854332983493805\n",
            "epoch: 12 step: 24 loss: 0.07259651273488998\n",
            "epoch: 12 step: 28 loss: 0.06995359063148499\n",
            "epoch: 12 step: 32 loss: 0.05642404407262802\n",
            "epoch: 13 step: 4 loss: 0.06813594698905945\n",
            "epoch: 13 step: 8 loss: 0.06943932175636292\n",
            "epoch: 13 step: 12 loss: 0.07070732116699219\n",
            "epoch: 13 step: 16 loss: 0.07399249821901321\n",
            "epoch: 13 step: 20 loss: 0.06854209303855896\n",
            "epoch: 13 step: 24 loss: 0.07259106636047363\n",
            "epoch: 13 step: 28 loss: 0.06996382027864456\n",
            "epoch: 13 step: 32 loss: 0.056423962116241455\n",
            "epoch: 14 step: 4 loss: 0.068134605884552\n",
            "epoch: 14 step: 8 loss: 0.06943826377391815\n",
            "epoch: 14 step: 12 loss: 0.07071228325366974\n",
            "epoch: 14 step: 16 loss: 0.07398047298192978\n",
            "epoch: 14 step: 20 loss: 0.06854820251464844\n",
            "epoch: 14 step: 24 loss: 0.07259637862443924\n",
            "epoch: 14 step: 28 loss: 0.0699550211429596\n",
            "epoch: 14 step: 32 loss: 0.0564248226583004\n",
            "epoch: 15 step: 4 loss: 0.06813421845436096\n",
            "epoch: 15 step: 8 loss: 0.06944184005260468\n",
            "epoch: 15 step: 12 loss: 0.07070493698120117\n",
            "epoch: 15 step: 16 loss: 0.07398676872253418\n",
            "epoch: 15 step: 20 loss: 0.06854896247386932\n",
            "epoch: 15 step: 24 loss: 0.07260262966156006\n",
            "epoch: 15 step: 28 loss: 0.0699484646320343\n",
            "epoch: 15 step: 32 loss: 0.05642811954021454\n",
            "epoch: 16 step: 4 loss: 0.0681382417678833\n",
            "epoch: 16 step: 8 loss: 0.06943951547145844\n",
            "epoch: 16 step: 12 loss: 0.07069848477840424\n",
            "epoch: 16 step: 16 loss: 0.0740077868103981\n",
            "epoch: 16 step: 20 loss: 0.06854455173015594\n",
            "epoch: 16 step: 24 loss: 0.07259722054004669\n",
            "epoch: 16 step: 28 loss: 0.06995566189289093\n",
            "epoch: 16 step: 32 loss: 0.05642877519130707\n",
            "epoch: 17 step: 4 loss: 0.0681353211402893\n",
            "epoch: 17 step: 8 loss: 0.06943586468696594\n",
            "epoch: 17 step: 12 loss: 0.07070570439100266\n",
            "epoch: 17 step: 16 loss: 0.07399341464042664\n",
            "epoch: 17 step: 20 loss: 0.06854430586099625\n",
            "epoch: 17 step: 24 loss: 0.07257772237062454\n",
            "epoch: 17 step: 28 loss: 0.07001208513975143\n",
            "epoch: 17 step: 32 loss: 0.056425001472234726\n",
            "epoch: 18 step: 4 loss: 0.06815594434738159\n",
            "epoch: 18 step: 8 loss: 0.06950803101062775\n",
            "epoch: 18 step: 12 loss: 0.07070139050483704\n",
            "epoch: 18 step: 16 loss: 0.07400394976139069\n",
            "epoch: 18 step: 20 loss: 0.06857842206954956\n",
            "epoch: 18 step: 24 loss: 0.07264993339776993\n",
            "epoch: 18 step: 28 loss: 0.06998087465763092\n",
            "epoch: 18 step: 32 loss: 0.05651599168777466\n",
            "epoch: 19 step: 4 loss: 0.0681883841753006\n",
            "epoch: 19 step: 8 loss: 0.06940951198339462\n",
            "epoch: 19 step: 12 loss: 0.07071638107299805\n",
            "epoch: 19 step: 16 loss: 0.0740022361278534\n",
            "epoch: 19 step: 20 loss: 0.06856194883584976\n",
            "epoch: 19 step: 24 loss: 0.07262536138296127\n",
            "epoch: 19 step: 28 loss: 0.06999842822551727\n",
            "epoch: 19 step: 32 loss: 0.056475818157196045\n",
            "epoch: 20 step: 4 loss: 0.06814464926719666\n",
            "epoch: 20 step: 8 loss: 0.06949149072170258\n",
            "epoch: 20 step: 12 loss: 0.07072722911834717\n",
            "epoch: 20 step: 16 loss: 0.07398615777492523\n",
            "epoch: 20 step: 20 loss: 0.06856562942266464\n",
            "epoch: 20 step: 24 loss: 0.07261428236961365\n",
            "epoch: 20 step: 28 loss: 0.06995943933725357\n",
            "epoch: 20 step: 32 loss: 0.05645923689007759\n",
            "epoch: 21 step: 4 loss: 0.06813202798366547\n",
            "epoch: 21 step: 8 loss: 0.06945580244064331\n",
            "epoch: 21 step: 12 loss: 0.07072971761226654\n",
            "epoch: 21 step: 16 loss: 0.07398248463869095\n",
            "epoch: 21 step: 20 loss: 0.06856614351272583\n",
            "epoch: 21 step: 24 loss: 0.07260841131210327\n",
            "epoch: 21 step: 28 loss: 0.06996254622936249\n",
            "epoch: 21 step: 32 loss: 0.05645589902997017\n",
            "epoch: 22 step: 4 loss: 0.06814175844192505\n",
            "epoch: 22 step: 8 loss: 0.06945279240608215\n",
            "epoch: 22 step: 12 loss: 0.07071129977703094\n",
            "epoch: 22 step: 16 loss: 0.07399932295084\n",
            "epoch: 22 step: 20 loss: 0.06855729222297668\n",
            "epoch: 22 step: 24 loss: 0.07260985672473907\n",
            "epoch: 22 step: 28 loss: 0.06995794177055359\n",
            "epoch: 22 step: 32 loss: 0.0564572811126709\n",
            "epoch: 23 step: 4 loss: 0.06814465671777725\n",
            "epoch: 23 step: 8 loss: 0.06944835186004639\n",
            "epoch: 23 step: 12 loss: 0.07071363180875778\n",
            "epoch: 23 step: 16 loss: 0.07400128245353699\n",
            "epoch: 23 step: 20 loss: 0.06855391710996628\n",
            "epoch: 23 step: 24 loss: 0.0726105123758316\n",
            "epoch: 23 step: 28 loss: 0.06995795667171478\n",
            "epoch: 23 step: 32 loss: 0.056458763778209686\n",
            "epoch: 24 step: 4 loss: 0.06814318895339966\n",
            "epoch: 24 step: 8 loss: 0.06945045292377472\n",
            "epoch: 24 step: 12 loss: 0.07071274518966675\n",
            "epoch: 24 step: 16 loss: 0.07399751245975494\n",
            "epoch: 24 step: 20 loss: 0.06855956465005875\n",
            "epoch: 24 step: 24 loss: 0.07261127233505249\n",
            "epoch: 24 step: 28 loss: 0.06995800882577896\n",
            "epoch: 24 step: 32 loss: 0.056458644568920135\n",
            "epoch: 25 step: 4 loss: 0.06814512610435486\n",
            "epoch: 25 step: 8 loss: 0.0694541484117508\n",
            "epoch: 25 step: 12 loss: 0.07071151584386826\n",
            "epoch: 25 step: 16 loss: 0.07400067150592804\n",
            "epoch: 25 step: 20 loss: 0.06855770945549011\n",
            "epoch: 25 step: 24 loss: 0.0726146399974823\n",
            "epoch: 25 step: 28 loss: 0.06995485723018646\n",
            "epoch: 25 step: 32 loss: 0.056463614106178284\n",
            "epoch: 26 step: 4 loss: 0.0681454986333847\n",
            "epoch: 26 step: 8 loss: 0.06944960355758667\n",
            "epoch: 26 step: 12 loss: 0.07071128487586975\n",
            "epoch: 26 step: 16 loss: 0.07400630414485931\n",
            "epoch: 26 step: 20 loss: 0.0685558021068573\n",
            "epoch: 26 step: 24 loss: 0.07261212915182114\n",
            "epoch: 26 step: 28 loss: 0.06996016949415207\n",
            "epoch: 26 step: 32 loss: 0.05646735429763794\n",
            "epoch: 27 step: 4 loss: 0.0681469738483429\n",
            "epoch: 27 step: 8 loss: 0.06945086270570755\n",
            "epoch: 27 step: 12 loss: 0.07071413099765778\n",
            "epoch: 27 step: 16 loss: 0.07399997115135193\n",
            "epoch: 27 step: 20 loss: 0.06856080889701843\n",
            "epoch: 27 step: 24 loss: 0.07261393964290619\n",
            "epoch: 27 step: 28 loss: 0.06995797157287598\n",
            "epoch: 27 step: 32 loss: 0.05646849423646927\n",
            "epoch: 28 step: 4 loss: 0.06814733147621155\n",
            "epoch: 28 step: 8 loss: 0.06945505738258362\n",
            "epoch: 28 step: 12 loss: 0.07071308046579361\n",
            "epoch: 28 step: 16 loss: 0.07400207221508026\n",
            "epoch: 28 step: 20 loss: 0.06856174021959305\n",
            "epoch: 28 step: 24 loss: 0.07261612266302109\n",
            "epoch: 28 step: 28 loss: 0.06995658576488495\n",
            "epoch: 28 step: 32 loss: 0.05647193267941475\n",
            "epoch: 29 step: 4 loss: 0.0681491419672966\n",
            "epoch: 29 step: 8 loss: 0.06945410370826721\n",
            "epoch: 29 step: 12 loss: 0.07070866227149963\n",
            "epoch: 29 step: 16 loss: 0.07401497662067413\n",
            "epoch: 29 step: 20 loss: 0.06855567544698715\n",
            "epoch: 29 step: 24 loss: 0.07261424511671066\n",
            "epoch: 29 step: 28 loss: 0.06996183097362518\n",
            "epoch: 29 step: 32 loss: 0.056473515927791595\n",
            "epoch: 30 step: 4 loss: 0.06814750283956528\n",
            "epoch: 30 step: 8 loss: 0.06945393234491348\n",
            "epoch: 30 step: 12 loss: 0.0707128643989563\n",
            "epoch: 30 step: 16 loss: 0.07400593161582947\n",
            "epoch: 30 step: 20 loss: 0.06856217980384827\n",
            "epoch: 30 step: 24 loss: 0.07261304557323456\n",
            "epoch: 30 step: 28 loss: 0.06996297836303711\n",
            "epoch: 30 step: 32 loss: 0.056472644209861755\n",
            "epoch: 31 step: 4 loss: 0.06814602762460709\n",
            "epoch: 31 step: 8 loss: 0.0694563239812851\n",
            "epoch: 31 step: 12 loss: 0.07071542739868164\n",
            "epoch: 31 step: 16 loss: 0.07400159537792206\n",
            "epoch: 31 step: 20 loss: 0.0685654878616333\n",
            "epoch: 31 step: 24 loss: 0.07261522114276886\n",
            "epoch: 31 step: 28 loss: 0.06996190547943115\n",
            "epoch: 31 step: 32 loss: 0.05647467076778412\n",
            "epoch: 32 step: 4 loss: 0.06814482063055038\n",
            "epoch: 32 step: 8 loss: 0.06945661455392838\n",
            "epoch: 32 step: 12 loss: 0.070712149143219\n",
            "epoch: 32 step: 16 loss: 0.07400810718536377\n",
            "epoch: 32 step: 20 loss: 0.06856272369623184\n",
            "epoch: 32 step: 24 loss: 0.07261168956756592\n",
            "epoch: 32 step: 28 loss: 0.06996463984251022\n",
            "epoch: 32 step: 32 loss: 0.05647552013397217\n",
            "epoch: 33 step: 4 loss: 0.06814044713973999\n",
            "epoch: 33 step: 8 loss: 0.06945532560348511\n",
            "epoch: 33 step: 12 loss: 0.07071459293365479\n",
            "epoch: 33 step: 16 loss: 0.07400496304035187\n",
            "epoch: 33 step: 20 loss: 0.06856507807970047\n",
            "epoch: 33 step: 24 loss: 0.07260869443416595\n",
            "epoch: 33 step: 28 loss: 0.06996563822031021\n",
            "epoch: 33 step: 32 loss: 0.056470759212970734\n",
            "epoch: 34 step: 4 loss: 0.06813527643680573\n",
            "epoch: 34 step: 8 loss: 0.0694626197218895\n",
            "epoch: 34 step: 12 loss: 0.07071241736412048\n",
            "epoch: 34 step: 16 loss: 0.07399304956197739\n",
            "epoch: 34 step: 20 loss: 0.06857883930206299\n",
            "epoch: 34 step: 24 loss: 0.07262250781059265\n",
            "epoch: 34 step: 28 loss: 0.06996037065982819\n",
            "epoch: 34 step: 32 loss: 0.056468650698661804\n",
            "epoch: 35 step: 4 loss: 0.06813162565231323\n",
            "epoch: 35 step: 8 loss: 0.06945941597223282\n",
            "epoch: 35 step: 12 loss: 0.07071948051452637\n",
            "epoch: 35 step: 16 loss: 0.07400298863649368\n",
            "epoch: 35 step: 20 loss: 0.0685797929763794\n",
            "epoch: 35 step: 24 loss: 0.07263173162937164\n",
            "epoch: 35 step: 28 loss: 0.06996633857488632\n",
            "epoch: 35 step: 32 loss: 0.05649600923061371\n",
            "epoch: 36 step: 4 loss: 0.06815415620803833\n",
            "epoch: 36 step: 8 loss: 0.06948064267635345\n",
            "epoch: 36 step: 12 loss: 0.07065290957689285\n",
            "epoch: 36 step: 16 loss: 0.0740562379360199\n",
            "epoch: 36 step: 20 loss: 0.06856158375740051\n",
            "epoch: 36 step: 24 loss: 0.07261951267719269\n",
            "epoch: 36 step: 28 loss: 0.06995514035224915\n",
            "epoch: 36 step: 32 loss: 0.05646773427724838\n",
            "epoch: 37 step: 4 loss: 0.06814686954021454\n",
            "epoch: 37 step: 8 loss: 0.06946580111980438\n",
            "epoch: 37 step: 12 loss: 0.07065840065479279\n",
            "epoch: 37 step: 16 loss: 0.07413884252309799\n",
            "epoch: 37 step: 20 loss: 0.06853391230106354\n",
            "epoch: 37 step: 24 loss: 0.07262248545885086\n",
            "epoch: 37 step: 28 loss: 0.0700262188911438\n",
            "epoch: 37 step: 32 loss: 0.05649549141526222\n",
            "epoch: 38 step: 4 loss: 0.06811926513910294\n",
            "epoch: 38 step: 8 loss: 0.0694020539522171\n",
            "epoch: 38 step: 12 loss: 0.07082031667232513\n",
            "epoch: 38 step: 16 loss: 0.07377329468727112\n",
            "epoch: 38 step: 20 loss: 0.06854763627052307\n",
            "epoch: 38 step: 24 loss: 0.07253193855285645\n",
            "epoch: 38 step: 28 loss: 0.07024596631526947\n",
            "epoch: 38 step: 32 loss: 0.05633768439292908\n",
            "epoch: 39 step: 4 loss: 0.06816257536411285\n",
            "epoch: 39 step: 8 loss: 0.06927783787250519\n",
            "epoch: 39 step: 12 loss: 0.07083327323198318\n",
            "epoch: 39 step: 16 loss: 0.07403356581926346\n",
            "epoch: 39 step: 20 loss: 0.06857192516326904\n",
            "epoch: 39 step: 24 loss: 0.07217481732368469\n",
            "epoch: 39 step: 28 loss: 0.07022556662559509\n",
            "epoch: 39 step: 32 loss: 0.05616658553481102\n",
            "epoch: 40 step: 4 loss: 0.06824973225593567\n",
            "epoch: 40 step: 8 loss: 0.06955061852931976\n",
            "epoch: 40 step: 12 loss: 0.07073771953582764\n",
            "epoch: 40 step: 16 loss: 0.07389301061630249\n",
            "epoch: 40 step: 20 loss: 0.06876617670059204\n",
            "epoch: 40 step: 24 loss: 0.07285190373659134\n",
            "epoch: 40 step: 28 loss: 0.06999942660331726\n",
            "epoch: 40 step: 32 loss: 0.056505702435970306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_uKOpe8IGJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b74c9c1-d3cc-4a78-c886-dfbeff60c38b"
      },
      "source": [
        "\"\"\"TEST\"\"\"\n",
        "def get_char_count(arg1):\n",
        "    c0 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
        "    c1 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
        "    c2 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
        "    c3 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
        "    c4 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
        "    c5 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
        "    c6 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
        "    return c0, c1, c2,c3, c4, c5, c6 \n",
        " \n",
        "\n",
        "\n",
        "char_correct = 0\n",
        "word_correct = 0\n",
        "total = 0\n",
        "\n",
        "betternet.eval()\n",
        "lstm.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for step, (img, label_oh, label) in enumerate(test_dl):\n",
        "        char_count =0\n",
        "        img = Variable(img).cuda()\n",
        "        label_oh = Variable(label_oh.float()).cuda()\n",
        "        #pred, feature = betternet(img)\n",
        "        pred= betternet(img)\n",
        "\n",
        "        label_len = label[0]\n",
        "        pred = pred.squeeze(0)\n",
        "        label_oh = label_oh.squeeze(0)\n",
        "        \n",
        "        c0,c1,c2,c3,c4,c5,c6 = get_char_count(pred.squeeze()) \n",
        "        d0,d1,d2,d3,d4,d5,d6 = get_char_count(label_oh) \n",
        "         \n",
        "        c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
        "        d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
        "        print(c)\n",
        "        print(d)\n",
        "        print(\" \")\n",
        "    \n",
        "        char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
        "        char_correct += char_count\n",
        "\n",
        "        if(bool(str(label[0]) in str(c))):\n",
        "            word_correct+=1\n",
        "\n",
        "        total += 1\n",
        "       \n",
        "print(100/7*char_correct/total)\n",
        "print(100*word_correct/total)\n",
        "\"\"\"END TEST\"\"\""
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35NONENONENONENONENONE\n",
            "b9xNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mbNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "d5q7qhNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6tl0kqv\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "t1NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "avhjn3z\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "74z0zNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "f1kfaNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "sripnsNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bg4NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "gmb45tz\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "sr5NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0ntNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lxfg98NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2b8oNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kr25NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "flNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0tiwrdNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "k5NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8kNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "gginNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qc6eNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "giz6rvNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "tf15NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7jzNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "v3zl9NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p78ecNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7rhNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "exqoNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yrsNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "siNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "n4tikmNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "l2c8pNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fixfNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "d0j1fNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "higmNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3qtyNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lnwNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kid92NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fgNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7u0NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qbdNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ofbNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zdnNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "sqvrcNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "xyx2z1NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bcdbxNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ejtNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "tl1zNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "pnNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2lNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5aip1NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8l5pwNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "q7uNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ht1kc5NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lpxdssw\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "hweg1gz\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ieNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "myNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qfcmgzd\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kfozxbNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ipNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "d3a0NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "z8359NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8cuNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mjnjd99\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lnNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "huetNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ahgjjuNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3m9hNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2nNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "edcui9NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "r3ifoNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "85280NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "29jxizNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5kxn1q7\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "54yb7qNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bv61bpv\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "okgNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "y2x1NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6nuuuct\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "f8m2rfNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lhNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "o6ekils\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "smbyyrNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5qNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "976dqNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "edvbdNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p3ilNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wdzlzNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "h0eNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "01NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wtrNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2ye9wrw\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3gNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "avvoNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "g6sNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lprkNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "95hqkvNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8gqu2NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "664ot5NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "c9NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qw3xkwb\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zyjhNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0eNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6uzkrNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "68NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "cpcmxNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ieox4lNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6pv3hNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "klNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2bNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1vwr6bc\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "xh9kp6i\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rzNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "h9gqvfp\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "asq5bkNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5eNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "n1w9NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rkfqsac\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5ucNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zj6zwNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "e6ziNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fi9ucm8\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "g5g8a7NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "larvNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "y6NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ebbxNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mw04NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zbNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3bNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "16b2xsj\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "jbuNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5khma0NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1xNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7apNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "jhij9v4\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ywqvk6NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kel3NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "azcjtjNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3jlafbg\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fghNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "x10vkvw\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "o4NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "vgqf7NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dun9kNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "x7kcr6s\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kzllNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "eyd5NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qlisNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zbvwbod\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "r8NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "9rmoc6NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "tqvlr9r\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "k3wsNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7ml7NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p3uNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "vpqfNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "78NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "65NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dychaNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "z9hjoNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rzaNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "12NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "z2z216NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2c1lNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "9su8zNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dj4rf5t\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rk4NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "98r0039\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1bsu19NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "xnc3jNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "xjgwNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "adzpmyNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "12dl0x0\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "joltNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "aftNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "49bxNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0lNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "34b5aNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "em08ooNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "69nvNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wnael4NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bjilouNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kolqNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "xgNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8k7x6ps\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bxpzzuNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5x2xakNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "b0htNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zgiry7b\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "w5cm9NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dk6lNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3hNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "hv2jycNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "f2NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "vciari4\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "nqczbNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kdaugNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dyNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kv0yNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "g00NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "vp0yvq0\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yl6wayi\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "hazeNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "moq1bNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ojzNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "hy7hNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fyipNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kv7NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "78NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "k9tNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dtl9y3h\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "joyi4m6\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ls6vNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5ktgwsNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "j4iNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kk1ogNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "r035okNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1ec72px\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "c7wNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "x257u6NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fyNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "gof8NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2qvkvsNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "uucx9NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "eu1fwfNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "e3NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dakNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "eobgNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "vs1NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ywNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "nq9gNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "j6e1pcNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "q02NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "to12NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "apdNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "swydkNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7de7dNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "v9s4cc5\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3wcNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8j1NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qwrhda2\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lg4sNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "da1NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "sjNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1suyf8NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fblzoNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "gvlhnNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0jj7wNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "e4o89rNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "clwllf0\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "nqNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "oljjeNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wjrvnuNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6k8s94NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "pjdNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ekgvmNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bo4m0NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ultrlrNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "t1NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kq865mNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5zw8NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3dNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "blvaodq\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0myqNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "4qdrNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ssjNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "y7NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1lxjdnl\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "szgNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ac8NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8qbNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5oNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lch0nrq\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "vf6cuvl\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "psNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "jwx51NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "x81tNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "hhg90zg\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "4ygmNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qiogNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "d0toxNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ts30NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rlt3NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6bgnNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "l9kmkuNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "52NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "54nqNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6b4NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yljpagn\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "weNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yy32nNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1csdcpb\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "dovtuNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "w4jn6NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "26g1ziNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ywwajNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2qhbrNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "4iep5NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "228l4NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yr1zarv\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fhf39lv\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wyNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "qpoNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "tj54zNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6rNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "plamweNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "d80f894\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "boifyf0\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "90zkcNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yg4NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "u0NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "naczNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "kveqlNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "euqjNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p71zNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "pzfk19NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lerNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lkxtNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "a1rNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5akquNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2bNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "57NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0x77agf\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2zNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "eaufcpNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "95d7ghNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zwNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zhaleNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zmbc1vNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p5k52x5\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "oeguap7\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ju08NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "lcodl32\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "oz1qzNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "4rNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3zNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "b0s6djNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5tn0NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ndNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ujvNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "obNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wbt5mvNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "01flbNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mtfNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3vxt2NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "uvNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "srNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yc9h1iNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "s3hNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "u9dgt6n\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "joccaNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "w1f4NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7coNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "f1NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "f74sNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "4v2o5uNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "k31sgl4\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "c3o7NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "pfNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5j4mNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "pfNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "i5hel3g\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wvNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "y0p29cNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "s9al4NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "m21wxNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3rozNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "jx7qiNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "5gzNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bi4NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "aziuaNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "iin0bdNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ttmcovu\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "k3nNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "b7iyNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "i0gNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "txNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "2ijjt22\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "egy7lna\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wmsarqo\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "tir7w2u\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "a8NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "flvhog9\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p5veuNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6r09gtb\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "yrswvmNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "aoNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "tzu3iuNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "haNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "l2i2xNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ru7l9lNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wguzNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fgibxNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "nijfbNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "b5nqgdNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7hNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "0bt4rNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zkfNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "objck5z\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3v2aNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "31cNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "n0vNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1sagap5\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "75NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "oh71qkNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "s3etNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3pcxkfNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "cult0NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "futtqoNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "4jiqNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bjNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rsdqkNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1a5NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "s28NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "rsd2NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "28v8quh\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "1nckk9r\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7vlayvv\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "r2mk4NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "32NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "00fc0pNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "gjwjtu2\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "g0iqabl\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mw7va5n\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6z2ppqr\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zzNONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "wl1jNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ngx1bfb\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "pmf4mpNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "cso60pNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mu51jNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "7m0dNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "p1p46rNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "jklNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "m4epNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "45gowNONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "fm47NONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "n6aNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "o3NONENONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "alqv1NONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "y79NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "h55z5aNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ujwNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "grbwNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "j56tqrNONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "ih6NONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6hzNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "91kxnk0\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "zzftNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "6m27rja\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "mlzkNONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "f1po1n9\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "3tyNONENONENONENONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "8axgj6NONE\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "bgntvuc\n",
            " \n",
            "35NONENONENONENONENONE\n",
            "blsNONENONENONENONE\n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-5294f4437315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlabel_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#pred, feature = betternet(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbetternet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlabel_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}